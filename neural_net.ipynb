{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras import layers\n",
    "import string\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandarallel import pandarallel\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"Dataset/Twitter/train.csv\", encoding = \"ISO-8859-1\",usecols=[0,5],header=None)\n",
    "test = pd.read_csv(\"Dataset/Twitter/test.csv\", encoding = \"ISO-8859-1\",usecols=[\"Sentiment\",\"SentimentText\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns = [\"target\",\"text\"]\n",
    "test.columns = [\"target\",\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['target'] = np.where(train['target']==4, 0, 1)\n",
    "test['target'] = np.where(test['target']==1, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    import preprocessor as p\n",
    "    processed_data = p.clean(input_data)\n",
    "    lowercase_value = processed_data.lower()\n",
    "    return lowercase_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 6 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b367343a84d47bfbf453a3bf4c4dce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=266667), Label(value='0 / 266667')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdd7b7b98e77451e84e57690764276fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=263103), Label(value='0 / 263103')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train[\"text\"] = train[\"text\"].parallel_apply(custom_standardization)\n",
    "test[\"text\"] = test[\"text\"].parallel_apply(custom_standardization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  dataframe = dataframe.copy()\n",
    "  labels = dataframe.pop('target')\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dataframe[\"text\"].values, labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_ds = df_to_dataset(train_df)\n",
    "raw_val_ds = df_to_dataset(test_df)\n",
    "raw_test_ds = df_to_dataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lables: tf.Tensor([1 1 1 1 1 0 1 0 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 1], shape=(32,), dtype=int32)\n",
      "Text: tf.Tensor(\n",
      "[b\"yeah, and the mazda mpv had the taurus' l duratec v6; i thought about one of those, but they don't make 'em anymore.\"\n",
      " b\"seriously?! why didn't you say so? lmao. tell me how.\"\n",
      " b'tried bleu cheese for the first time in a long time. i am not sure how the tummy is accepting this.'\n",
      " b\"idk n their mic doesn't work to well apparently. so, disneyland!!!\"\n",
      " b\"ok i'm bored... wat shall i do? rly wish i can drive\"\n",
      " b'no man no man no man no man!!!'\n",
      " b\"ma3arf it's like yom kan yrmes an what was wrong in the presentations kel el comments aggi w ana el wa7eeda eli ys2alni!\"\n",
      " b'oh man i love that place...enjoy it'\n",
      " b\"yea...dad hijacked the putah. i'm off for tonight my lovelies. -\"\n",
      " b'got woken up early by my dog...'\n",
      " b'hope i can get out of this meeting early...i need to find a home'\n",
      " b\"i have arrived in la. waitin on my bags. lax aint as big as hartsfield jackson tho! i'm excited to smell cali air\"\n",
      " b\"i wish i could of been at commencement this yr i wonder if they're really going to protest.\"\n",
      " b'my matress just yelled at me to get my disgusting filth off of it'\n",
      " b'so...did you get rained on?'\n",
      " b\"f !!! we had a f director which didn't know how to direct ... now we will not b able to show a movie\"\n",
      " b'okay finished the methodology, findings and discussion and conclusion and references... now to write the intro and lit review'\n",
      " b'tequila? i prevented lol you had to experience it by yourself. as about me it was my st and last time tasting, once was enough'\n",
      " b'mazel tov on your news!'\n",
      " b'missed jason so much while he was working today seeing him tomorrow though'\n",
      " b'i just spent $3 on a lifetime supply of animal crackers. oh happy day! olive garden now'\n",
      " b'is not twitter material.'\n",
      " b'perhaps... does it bode well for my apprenticeship application?'\n",
      " b'im sorry you broke them. you can put them back in if it makes things work'\n",
      " b\"brought efa shopping to keep me company while celeste shops. now he and her are shopping and i'm still alone\"\n",
      " b\"caffeine withdrawal is horrible- i've been there. hang in there. treat yourself to something else today!\"\n",
      " b'so does voltaic come out on the rd or the th? not soon enough either way'\n",
      " b\"my dwarf rabbit pee'd on me!\" b'ill be lucky to get to las by tues'\n",
      " b'going to a wake. r.i.p. mr. gamboa'\n",
      " b'de maine pot juca sims , acum am mouse thanks'\n",
      " b'i know, it was so beautiful - unfortunately i am home now! want to go back!'], shape=(32,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for feature_batch, label_batch in raw_train_ds.take(1):\n",
    "  print('Lables:', label_batch )\n",
    "  print('Text:', feature_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches in raw_train_ds: 40000\n",
      "Number of batches in raw_val_ds: 10000\n",
      "Number of batches in raw_test_ds: 49332\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of batches in raw_train_ds: {raw_train_ds.cardinality()}\")\n",
    "print(f\"Number of batches in raw_val_ds: {raw_val_ds.cardinality()}\")\n",
    "print(f\"Number of batches in raw_test_ds: {raw_test_ds.cardinality()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model constants.\n",
    "max_features = 200000\n",
    "embedding_dim = 128\n",
    "sequence_length = 500\n",
    "vectorize_layer = TextVectorization(\n",
    "    max_tokens=max_features,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ds = raw_train_ds.map(lambda x, y: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return vectorize_layer(text), label\n",
    "\n",
    "\n",
    "# Vectorize the data.\n",
    "train_ds = raw_train_ds.map(vectorize_text)\n",
    "val_ds = raw_val_ds.map(vectorize_text)\n",
    "test_ds = raw_test_ds.map(vectorize_text)\n",
    "\n",
    "# Do async prefetching / buffering of the data for best performance on GPU.\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=10)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=10)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 0 1 0 1 1 0 1 0 1 0 1 0 0 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 0], shape=(32,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[   64   160    31 ...     0     0     0]\n",
      " [  127   128   199 ...     0     0     0]\n",
      " [   45     3   141 ...     0     0     0]\n",
      " ...\n",
      " [  316   394     0 ...     0     0     0]\n",
      " [   39    77   603 ...     0     0     0]\n",
      " [  898 22161    52 ...     0     0     0]], shape=(32, 500), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for feature_batch,label_batch in train_ds.take(1):\n",
    "    print(label_batch)\n",
    "    print(feature_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A integer input for vocab indices.\n",
    "inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
    "\n",
    "# Next, we add a layer to map those vocab indices into a space of dimensionality\n",
    "# 'embedding_dim'.\n",
    "x = layers.Embedding(max_features, embedding_dim)(inputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Conv1D + global max pooling\n",
    "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "predictions = layers.Dense(1, activation=\"sigmoid\", name=\"predictions\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, predictions)\n",
    "\n",
    "# Compile the model with binary crossentropy loss and an adam optimizer.\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 644s 16ms/step - loss: 0.4376 - accuracy: 0.7994 - val_loss: 0.4025 - val_accuracy: 0.8168\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 627s 16ms/step - loss: 0.4018 - accuracy: 0.8213 - val_loss: 0.3984 - val_accuracy: 0.8202\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 645s 16ms/step - loss: 0.3881 - accuracy: 0.8293 - val_loss: 0.3989 - val_accuracy: 0.8213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a612f78520>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "# Fit the model using the train and test datasets.\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49332/49332 [==============================] - 165s 3ms/step - loss: 0.3614 - accuracy: 0.8399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3614481985569, 0.8398500084877014]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame({\"text\":[\"I want to kill myself\"],\"target\":[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_ds = df_to_dataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 49336 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A608DB4670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 105ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.8786312]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A string input\n",
    "inputs = tf.keras.Input(shape=(1,), dtype=\"string\")\n",
    "# Turn strings into vocab indices\n",
    "indices = vectorize_layer(inputs)\n",
    "# Turn vocab indices into predictions\n",
    "outputs = model(indices)\n",
    "\n",
    "# Our end to end model\n",
    "end_to_end_model = tf.keras.Model(inputs, outputs)\n",
    "end_to_end_model.compile(\n",
    "    loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Test it with `raw_test_ds`, which yields raw strings\n",
    "\n",
    "end_to_end_model.predict(new_test_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "176c0334d7b9c7a9b7eb6fa04d96d8bb263ed7a5a425eb1172d4f16fe7b04889"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
